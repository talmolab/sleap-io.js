{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":""},{"location":"#sleap-iojs","title":"sleap-io.js","text":"<p>JavaScript/TypeScript utilities for reading and writing SLEAP <code>.slp</code> files with streaming-friendly access patterns and a lightweight data model.</p>"},{"location":"#quick-start","title":"Quick start","text":"<pre><code>npm install\nnpm run build\n</code></pre> <pre><code>import { loadSlp, saveSlp } from \"@talmolab/sleap-io.js\";\n\nconst labels = await loadSlp(\"/path/to/session.slp\", { openVideos: false });\nawait saveSlp(labels, \"/tmp/session-roundtrip.slp\", { embed: false });\n</code></pre>"},{"location":"#why-this-project","title":"Why this project","text":"<ul> <li>Bring SLP parsing to browser and serverless environments.</li> <li>Keep large file workflows streaming-first.</li> <li>Mirror the sleap-io data model and codec behaviors in JS.</li> </ul>"},{"location":"#features","title":"Features","text":"<ul> <li>SLP read/write with embedded frame support.</li> <li>Streaming inputs (URL, <code>File</code>, <code>FileSystemFileHandle</code>).</li> <li>Data model types (<code>Labels</code>, <code>LabeledFrame</code>, <code>Instance</code>, <code>Skeleton</code>, <code>Video</code>).</li> <li>Dictionary and numpy codecs.</li> </ul>"},{"location":"#environments","title":"Environments","text":"<ul> <li>Static SPA: Browser-only usage with URL streaming or File System Access API.</li> <li>Server/Worker: Stream from URLs or byte buffers for containerized runtimes.</li> <li>Local Node/Electron: Optional local filesystem access for <code>.slp</code> paths.</li> </ul>"},{"location":"#links","title":"Links","text":"<ul> <li>Python sleap-io: https://github.com/talmolab/sleap-io</li> <li>Docs: https://io.sleap.ai</li> </ul>"},{"location":"api/","title":"API","text":""},{"location":"api/#api-reference","title":"API Reference","text":"<p>This document covers the public API exported from <code>src/index.ts</code>. All examples assume: <pre><code>import {\n  loadSlp,\n  saveSlp,\n  loadVideo,\n  Video,\n  Mp4BoxVideoBackend,\n  Labels,\n  LabeledFrame,\n  Instance,\n  PredictedInstance,\n  Skeleton,\n  Track,\n  LabelsSet,\n  SuggestionFrame,\n  toDict,\n  fromDict,\n  toNumpy,\n  fromNumpy,\n} from \"@talmolab/sleap-io.js\";\n</code></pre></p>"},{"location":"api/#core-io","title":"Core I/O","text":""},{"location":"api/#loadslpsource-options","title":"<code>loadSlp(source, options)</code>","text":"<p>Read <code>.slp</code> from a path, URL, <code>File</code>, <code>FileSystemFileHandle</code>, or byte buffer.</p> <pre><code>const labels = await loadSlp(\"/data/session.slp\", {\n  openVideos: false,\n  h5: { stream: \"auto\", filenameHint: \"session.slp\" },\n});\n</code></pre> <ul> <li><code>source</code>: string path/URL, <code>File</code>, <code>FileSystemFileHandle</code>, <code>Uint8Array</code>, or <code>ArrayBuffer</code>.</li> <li><code>options.openVideos</code> (default <code>true</code>): set <code>false</code> to skip opening video backends.</li> <li><code>options.h5.stream</code>: <code>\"auto\" | \"range\" | \"download\"</code> (browser URL streaming).</li> <li><code>options.h5.filenameHint</code>: helps name temporary files.</li> </ul>"},{"location":"api/#saveslplabels-filename-options","title":"<code>saveSlp(labels, filename, options)</code>","text":"<p>Write <code>.slp</code> (Node/Electron).</p> <pre><code>await saveSlp(labels, \"/tmp/roundtrip.slp\", {\n  embed: false,\n  restoreOriginalVideos: true,\n});\n</code></pre> <ul> <li><code>options.embed</code>: embed frames (<code>true</code>, <code>false</code>, or dataset name).</li> <li><code>options.restoreOriginalVideos</code> (default <code>true</code>): keep original video paths.</li> </ul>"},{"location":"api/#loadvideofilename-options","title":"<code>loadVideo(filename, options)</code>","text":"<p>Open a <code>Video</code> with an appropriate backend.</p> <pre><code>const video = await loadVideo(\"/data/movie.mp4\", { openBackend: true });\nconst frame0 = await video.getFrame(0);\nvideo.close();\n</code></pre> <ul> <li><code>options.dataset</code>: dataset path for embedded HDF5 sources.</li> <li><code>options.openBackend</code> (default <code>true</code>): set <code>false</code> for deferred open.</li> </ul>"},{"location":"api/#video-backends","title":"Video Backends","text":""},{"location":"api/#video","title":"<code>Video</code>","text":"<p><code>Video</code> wraps a backend and exposes <code>shape</code>, <code>fps</code>, <code>getFrame</code>, <code>getFrameTimes</code>, and <code>close</code>.</p> <pre><code>const video = await loadVideo(\"/data/movie.mp4\");\nconst timestamps = await video.getFrameTimes(); // number[] | null\n</code></pre> <ul> <li><code>getFrameTimes()</code> returns <code>null</code> if the backend does not implement it.</li> </ul>"},{"location":"api/#mp4boxvideobackend","title":"<code>Mp4BoxVideoBackend</code>","text":"<p>Browser-only backend for <code>.mp4</code> with WebCodecs + mp4box. Supports range requests when the server honors <code>Range</code> and falls back to full download.</p> <pre><code>const backend = new Mp4BoxVideoBackend(\"/data/movie.mp4\");\nconst video = new Video({ filename: \"/data/movie.mp4\", backend });\nconst t = await video.getFrameTimes();\n</code></pre> <p>Notes: - Requires WebCodecs (<code>VideoDecoder</code>, <code>EncodedVideoChunk</code>). - Uses HEAD + <code>Range: bytes=0-0</code> probe to detect range support. - Provides precise frame timestamps via <code>getFrameTimes()</code>.</p>"},{"location":"api/#hdf5videobackend","title":"<code>Hdf5VideoBackend</code>","text":"<p>Used for <code>.slp</code>, <code>.h5</code>, or <code>.hdf5</code> sources (embedded frames).</p> <ul> <li>Selected automatically by <code>loadVideo()</code> for HDF5 inputs.</li> <li>Decodes embedded PNG/JPEG frames in browsers; raw frames require <code>shape</code> + <code>channelOrder</code>.</li> </ul>"},{"location":"api/#mediavideobackend","title":"<code>MediaVideoBackend</code>","text":"<p>Browser fallback when WebCodecs/mp4box is unavailable.</p> <ul> <li>Uses <code>HTMLVideoElement</code> + canvas.</li> <li>No <code>getFrameTimes()</code> support.</li> </ul>"},{"location":"api/#labels-model-classes","title":"Labels &amp; Model Classes","text":"<p>Key types:</p> <ul> <li><code>Labels</code>, <code>LabeledFrame</code>, <code>Instance</code>, <code>PredictedInstance</code></li> <li><code>Skeleton</code>, <code>Track</code></li> <li><code>Video</code>, <code>SuggestionFrame</code>, <code>LabelsSet</code></li> <li><code>Camera</code>, <code>CameraGroup</code>, <code>RecordingSession</code> (camera utilities)</li> </ul> <pre><code>const skeleton = new Skeleton([\"nose\", \"tail\"]);\nconst inst = Instance.fromArray([[10, 20], [30, 40]], skeleton);\nconst video = new Video({ filename: \"/data/movie.mp4\" });\nconst frame = new LabeledFrame({ video, frameIdx: 0, instances: [inst] });\nconst labels = new Labels({ labeledFrames: [frame], skeletons: [skeleton], videos: [video] });\n</code></pre>"},{"location":"api/#codecs-numpy-helpers","title":"Codecs &amp; Numpy Helpers","text":""},{"location":"api/#dictionary-codec","title":"Dictionary codec","text":"<pre><code>const dict = toDict(labels);\nconst restored = fromDict(dict);\n</code></pre>"},{"location":"api/#numpy-codec","title":"Numpy codec","text":"<pre><code>const array = toNumpy(labels, { returnConfidence: true });\nconst rebuilt = fromNumpy(array, { video, skeleton, returnConfidence: true });\n</code></pre> <p>Also available: - <code>Labels.numpy({ video, returnConfidence })</code> - <code>Labels.fromNumpy(data, { video, skeleton, trackNames, firstFrame })</code></p>"},{"location":"api/#streaming-options","title":"Streaming Options","text":"<p>SLP streaming is handled by HDF5 open helpers:</p> <pre><code>const labels = await loadSlp(\"https://example.com/session.slp\", {\n  openVideos: false,\n  h5: { stream: \"range\", filenameHint: \"session.slp\" },\n});\n</code></pre> <ul> <li><code>stream: \"auto\"</code> uses range streaming when available.</li> <li><code>stream: \"download\"</code> forces full file download.</li> <li>Node only supports string paths or byte buffers for SLP inputs.</li> <li>Browser supports URL, <code>File</code>, <code>FileSystemFileHandle</code>, or byte buffers.</li> </ul>"},{"location":"api/#error-handling-notes","title":"Error Handling Notes","text":"<p>Common runtime errors to anticipate:</p> <ul> <li>SLP parsing:</li> <li>Missing <code>/metadata</code> group in invalid <code>.slp</code>.</li> <li>Unsupported source type in browser or Node.</li> <li>Failed fetch for remote SLP (bad URL/status).</li> <li> <p><code>h5wasm</code> FS unavailable in unsupported environments.</p> </li> <li> <p>MP4/WebCodecs:</p> </li> <li>WebCodecs not supported or non-browser environment.</li> <li>No video tracks or unsupported codec.</li> <li> <p>Failed fetch or no video source available.</p> </li> <li> <p>Media backend:</p> </li> <li>Browser-only usage.</li> <li>Video load or seek failures.</li> </ul>"},{"location":"demo/","title":"Demo","text":""},{"location":"demo/#demo","title":"Demo","text":"<p>The embedded viewer below loads <code>.slp</code> files entirely in the browser. It streams the demo SLP and MP4 using range requests when available.</p> <p> </p>"}]}